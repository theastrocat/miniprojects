{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import words\n",
    "word_list = words.words?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an attempt to look at the differences between two words based off of the keyboard layout of your computer. It uses graph theory to look at the shortest path between two characters on your keyboard.\n",
    "\n",
    "**key_graph** : A dictionary of keyboard characters, where the values are lists of the neighbors.\n",
    "\n",
    "**breadth_first** : A simple breadth first search algorithm to find the shortest path between characters in key_graph.\n",
    "\n",
    "**find_difference** : Breaks words/word segments up into single characters then passes them into the breadth first algorithm and then finds legth of the shortest path, that path is the character's difference 'score'. The scores are summed for the entire word and divided by the length of the word to give a word/segment difference score.\n",
    "\n",
    "**compare_words** : Compares the differences between the lengths of the two words, if they are different, passes them into the `find_differences` function by shortest word chunk of the longer word. eg: `compare_words(\"cat\", \"course\")` passes `(\"cat\", \"cou\")` ,  `(\"cat\", \"our\")`, `(\"cat\", \"urs\")`, and `(\"cat\", \"rse\")` into `find_differences`. Then finds the best scoring segment, then adds a penalty of $\\frac{|len(w1) - len(w2)|}{len(w1)}$ to the lowest score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "key_graph = {\"q\" : [\"w\", \"a\"],\n",
    "             \"w\" : [\"q\", \"a\", \"s\", \"e\"],\n",
    "             \"e\" : [\"w\", \"s\", \"d\", \"r\"],\n",
    "             \"r\" : [\"e\", \"d\", \"f\", \"t\"],\n",
    "             \"t\" : [\"r\", \"f\", \"g\", \"y\"],\n",
    "             \"y\" : [\"t\", \"g\", \"h\", \"u\"],\n",
    "             \"u\" : [\"y\", \"h\", \"j\", \"i\"],\n",
    "             \"i\" : [\"u\", \"j\", \"k\", \"o\"],\n",
    "             \"o\" : [\"i\", \"k\", \"l\", \"p\"],\n",
    "             \"p\" : [\"o\", \"l\"],\n",
    "             \"a\" : [\"q\", \"w\", \"s\", \"z\"],\n",
    "             \"s\" : [\"a\", \"w\", \"e\", \"d\", \"x\", \"z\"],\n",
    "             \"d\" : [\"s\", \"e\", \"r\", \"f\", \"c\", \"x\"],\n",
    "             \"f\" : [\"d\", \"r\", \"t\", \"g\", \"v\", \"c\"],\n",
    "             \"g\" : [\"f\", \"t\", \"y\", \"h\", \"b\", \"v\"],\n",
    "             \"h\" : [\"g\", \"y\", \"u\", \"j\", \"n\", \"b\"],\n",
    "             \"j\" : [\"h\", \"u\", \"i\", \"k\", \"m\", \"n\"],\n",
    "             \"k\" : [\"j\", \"i\", \"o\", \"l\", \"m\"],\n",
    "             \"l\" : [\"k\", \"o\", \"p\"],\n",
    "             \"z\" : [\"a\", \"s\", \"x\"],\n",
    "             \"x\" : [\"z\", \"s\", \"d\", \"c\"],\n",
    "             \"c\" : [\"x\", \"d\", \"f\", \"v\"],\n",
    "             \"v\" : [\"c\", \"f\", \"g\", \"b\"],\n",
    "             \"b\" : [\"v\", \"g\", \"h\", \"n\"],\n",
    "             \"n\" : [\"b\", \"h\", \"j\", \"m\"],\n",
    "             \"m\" : [\"n\", \"j\", \"k\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def breadth_first(graph,start, end):\n",
    "    \"\"\"\n",
    "    Breadth First Search Algorithm.\n",
    "    Returns shortest path.\n",
    "    -------------------------------------\n",
    "    Inputs:\n",
    "        graph : Dictionary of connecting nodes\n",
    "        start : Starting point on the graph\n",
    "        end   : Ending point on the graph\n",
    "    Outputs:\n",
    "        path  : List of shortest path\n",
    "    \"\"\"\n",
    "    queue = []\n",
    "    queue.append([start])\n",
    "    while queue:\n",
    "        path = queue.pop(0)\n",
    "        node = path[-1]\n",
    "        if node == end:\n",
    "            return path\n",
    "        for adjacent in graph.get(node, []):\n",
    "            new_path = list(path)\n",
    "            new_path.append(adjacent)\n",
    "            queue.append(new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_difference(seg1, seg2):\n",
    "    letter_score = []\n",
    "    for c1,c2 in zip(seg1, seg2):\n",
    "        letter_score.append(float(len(breadth_first(key_graph, c1, c2)) - 1))\n",
    "    return sum(letter_score)/len(letter_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compare_words(word1, word2):\n",
    "    word1 = word1.lower()\n",
    "    word2 = word2.lower()\n",
    "    seg_scores = []\n",
    "    if len(word1) >= len(word2):\n",
    "        for i in range(0, len(word1) - len(word2) + 1):\n",
    "            seg_scores.append(find_difference(word1[i:i+len(word2)], word2))\n",
    "    else:\n",
    "        for i in range(0, len(word2) - len(word1) + 1):\n",
    "            seg_scores.append(find_difference(word1[i:i+len(word2)], word2))\n",
    "    return round(min(seg_scores) + abs(len(word1) - len(word2))/float(len(word1)),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pprint as pp\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import numpy as np\n",
    "client = MongoClient()\n",
    "db = client.nyt_dump\n",
    "coll = db.articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopwords_ = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keywords = {}\n",
    "for num, document in enumerate(coll.find()):\n",
    "    temp_content = ''.join(document['content']).encode('ascii','ignore').replace('\\n', '')\n",
    "    tokens = nltk.word_tokenize(temp_content)\n",
    "    result = [x for x in tokens if x not in stopwords_ and x.isalpha()]\n",
    "    keywords[num] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_list = set()\n",
    "for l in keywords.values():\n",
    "    word_list = word_list | set(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_list = list(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkword = \"covfefe\"\n",
    "thresh = 1 #How many letters am I willing to go out to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-fce8dbb78ae8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mword_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompare_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mword_score\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mbest_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-5cd56eb8e84e>\u001b[0m in \u001b[0;36mcompare_words\u001b[0;34m(word1, word2)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mseg_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfind_difference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-b6ead2e5169a>\u001b[0m in \u001b[0;36mfind_difference\u001b[0;34m(seg1, seg2)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mletter_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mc1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mletter_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbreadth_first\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mletter_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mletter_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-0917328f4a1f>\u001b[0m in \u001b[0;36mbreadth_first\u001b[0;34m(graph, start, end)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_words = []\n",
    "for ind, word in enumerate(word_list):\n",
    "    if ind % 100 == 0:\n",
    "        print ind\n",
    "    if len(word) <= (len(checkword) + thresh) and len(word) >= (len(checkword) - thresh):\n",
    "        word_score = compare_words(checkword, word)\n",
    "        if word_score <= 2.0:\n",
    "            best_words.append([word_score,word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "273"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(best_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39335"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.64, 'coffee'],\n",
       " [0.71, 'conceded'],\n",
       " [0.71, 'differed'],\n",
       " [0.86, 'corseted'],\n",
       " [0.98, 'overseas'],\n",
       " [1.0, 'contend'],\n",
       " [1.0, 'corrects'],\n",
       " [1.0, 'diverse'],\n",
       " [1.14, 'Cutter'],\n",
       " [1.14, 'Preece'],\n",
       " [1.14, 'bothers'],\n",
       " [1.14, 'buffer'],\n",
       " [1.14, 'courses'],\n",
       " [1.14, 'ringers'],\n",
       " [1.14, 'sitters'],\n",
       " [1.29, 'Couture'],\n",
       " [1.29, 'budgets'],\n",
       " [1.29, 'contents'],\n",
       " [1.29, 'couture'],\n",
       " [1.29, 'hovered'],\n",
       " [1.31, 'Indeed'],\n",
       " [1.31, 'Odette'],\n",
       " [1.31, 'Orsett'],\n",
       " [1.31, 'Rouget'],\n",
       " [1.31, 'binder'],\n",
       " [1.31, 'funded'],\n",
       " [1.31, 'invert'],\n",
       " [1.31, 'onscreen'],\n",
       " [1.31, 'peters'],\n",
       " [1.31, 'singer'],\n",
       " [1.43, 'Concerns']]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(best_words)[:31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
